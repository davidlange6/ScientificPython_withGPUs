{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e39776f-07e4-4674-94f2-7b652ef3e7c3",
   "metadata": {},
   "source": [
    "# Lesson 5 project: Histograms and Monte Carlo on GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c6264-b8be-462b-adbb-d4cb2d60d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import numba as nb\n",
    "import numba.cuda\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "from hist import Hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa2e35-da4f-45e1-ac0a-c99bfe309cc9",
   "metadata": {},
   "source": [
    "The three exercises below are independent: you can start with whichever one you want.\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fca08-6c5b-4886-ba53-063bf738a12f",
   "metadata": {},
   "source": [
    "## Exercise 1: make a CUDA kernel with Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695bf69-f8ce-4aba-85de-48c853d02397",
   "metadata": {},
   "source": [
    "We'll use the non-ragged data from [lesson-2-project.ipynb](lesson-2-project.ipynb) by casting each array from an HDF5 file as CuPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756114ee-0028-4a36-9cd7-269ead9bcff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hdf5 = h5py.File(\"data/SMHiggsToZZTo4L.h5\")\n",
    "e1_pt = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e1\"][\"pt\"])\n",
    "e1_phi = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e1\"][\"phi\"])\n",
    "e1_eta = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e1\"][\"eta\"])\n",
    "e2_pt = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e2\"][\"pt\"])\n",
    "e2_phi = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e2\"][\"phi\"])\n",
    "e2_eta = cp.asarray(dataset_hdf5[\"ee_mumu\"][\"e2\"][\"eta\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533554c4-fbe0-4d28-aafd-312969301fdf",
   "metadata": {},
   "source": [
    "We can use CuPy's array interface to compute the mass with\n",
    "\n",
    "$$\\sqrt{2\\,{p_T}_1\\,{p_T}_2\\left(\\cosh(\\eta_1 - \\eta_2) - \\cos(\\phi_1 - \\phi_2)\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf4d0f-0302-4bf3-bf2a-d37763d92a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mass = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e0b3c-ea20-43fe-bd0f-8b31fb188f7b",
   "metadata": {},
   "source": [
    "Now implement the same as a single kernel with Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36421aea-f252-401e-a2bc-19fe7e9f51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def compute_z_mass(...):\n",
    "    ...\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f2a029-d01e-459d-8d46-5e924e2cca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run compute_z_mass and store the computed Z mass in a variable called z_mass_numba\n",
    "....\n",
    "\n",
    "compute_z_mass....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1eb66-9fed-487f-9310-6b739e7d9cf1",
   "metadata": {},
   "source": [
    "And finally make a plot of each. Here is a histogram definition to get you started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d1fd0-2f75-43f7-acf5-3079f01f57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "z_mass_numba = z_mass\n",
    "Hist.new.Reg(120, 0, 120, name=\"e+e- mass (GeV)\").Double().fill(z_mass.get()).plot()\n",
    "\n",
    "# are the two histograms correctly overlaid? Eg, \n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc1fc3-67b1-46b5-9f95-a5d3b52f1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "z_mass_numba = z_mass\n",
    "Hist.new.Reg(120, 0, 120, name=\"e+e- mass (GeV)\").Double().fill(z_mass_numba.get()).plot()\n",
    "\n",
    "# are the two histograms the same??\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f7b9b-6e7f-47a4-8be6-7638b1e901eb",
   "metadata": {},
   "source": [
    "## Exercise 2: fill a histogram on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d4a35-364e-4db3-90e6-524272d6332c",
   "metadata": {},
   "source": [
    "This time, you'll fill the histogram on the GPU and only copy the filled bin contents from GPU to RAM.\n",
    "\n",
    "The dataset is larger, 10 million dimuon masses. Pretend that the histogram code you're writing will be applied to data that was computed on the GPU, to avoid a costly data transfer before reducing it to a small set of bin contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b93c0-00ff-4c18-8f20-137dacd48122",
   "metadata": {},
   "outputs": [],
   "source": [
    "with uproot.open(\"data/dimuon_mass.root:tree/mass\") as branch:\n",
    "    dimuon_mass = cp.asarray(branch.array(library=\"np\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c0021-61c1-4d1c-b934-371475f2f663",
   "metadata": {},
   "source": [
    "The histogram will have 1200 bins and cover a range from 0 to 120 GeV, with the overflows going in the nearest edge bin. Thus, the mass-to-bin calculation is simple:\n",
    "\n",
    "```python\n",
    "bin_index = int(mass * 10)\n",
    "if bin_index < 0:\n",
    "    bin_index = 0\n",
    "elif bin_index >= 1200:\n",
    "    bin_index = 1199\n",
    "```\n",
    "\n",
    "and the plot should look like\n",
    "\n",
    "![](img/lesson-5-exercise-2-expectation.png)\n",
    "\n",
    "The histogram bins is another array that you'll pass to the Numba-based kernel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a35f3-6280-4e96-b7d2-44fd6ab50d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_values = cp.zeros(1200, dtype=cp.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52221b-6b2a-4f15-a988-15ee7415cb33",
   "metadata": {},
   "source": [
    "CUDA supplies some atomic operations and Numba makes them available as `nb.cuda.atomic.*` ([see documentation](https://numba.readthedocs.io/en/stable/cuda/intrinsics.html)). Which one(s) would be useful here?\n",
    "\n",
    "Note that atomic operations are only defined for a limited set of numeric data types (`dtype`). If you need to define `bin_values` as an unsigned integer, go ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d79e6-e109-46ee-8abe-75c1a3ee346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def fill_histogram(...):\n",
    "        ...\n",
    "\n",
    "...\n",
    "\n",
    "fill_histogram ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d7a88-d346-4372-97d6-1e85193b33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "h = Hist.new.Reg(1200, 0, 120, label=\"dimuon mass (GeV)\").Double()\n",
    "h.values()[:] = bin_values.get()\n",
    "h.plot(ax=ax)\n",
    "\n",
    "ax.set_xlim(0, 120)\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e961e-ae44-4ea3-8036-4bf3abf85443",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f3210-f1bb-4f90-92ec-7d7055a9d9d6",
   "metadata": {},
   "source": [
    "## Exercise 3: use Monte Carlo to calculate π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03dd6b-150b-467e-9570-195b0ad47ced",
   "metadata": {},
   "source": [
    "All of the examples we've seen so far use the GPU to analyze data. What if you want to generate Monte Carlo samples?\n",
    "\n",
    "Random numbers need to be used carefully with parallel processing, since it's easy to accidentally generate the same (or correlated) random numbers on different processors, which invalidates the result in hard-to-discover ways. This is because \"random numbers\" really means \"arbitrary numbers\", since a GPU, like any other computational device, is deterministic. A sequence of \"random numbers\" is a sequence that would be unsurprising if we were expecting a uniformly distributed, statistically independent set.\n",
    "\n",
    "For instance, if we copied a NumPy random number generator to two processes running in parallel,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc038cc-7c5b-4be7-8c4f-2f20f93b4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng1 = np.random.default_rng()\n",
    "rng2 = copy.deepcopy(rng1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc31c0e-3e8f-4b11-ad79-06f874a4188f",
   "metadata": {},
   "source": [
    "both processes would generate the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418d011-f8c1-4a0b-b6ec-02431d9601d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng1.integers(0, 100, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5acab-b187-44bd-a1d0-8914f209d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng2.integers(0, 100, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002268b5-2f49-4b77-97b0-fda791937c0c",
   "metadata": {},
   "source": [
    "To prevent this, [np.random.Generator](https://numpy.org/doc/stable/reference/random/generator.html) has a [spawn](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.spawn.html) method, which makes a set of generators that are guaranteed independent and uncorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a966a-45c1-4312-9f62-42c9733a4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "rng1, rng2 = rng.spawn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71907538-aed2-43d7-9679-676608807ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng1.integers(0, 100, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef5b37-4a05-4e03-8799-1e3ac0559408",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng2.integers(0, 100, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086cad85-3d16-45a4-b39c-36a0e4eb4ac9",
   "metadata": {},
   "source": [
    "(The correlation coefficient is about 0.001 for off-diagonal elements in a set of a million Gaussian-distributed values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00165e-323a-4d20-b75c-8f907daf3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(rng1.normal(0, 1, 1000000), rng2.normal(0, 1, 1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b6626-34bb-425a-81c6-7a3d72e892cb",
   "metadata": {},
   "source": [
    "For a GPU kernel, we need to spawn as many random number generators as we have threads. For a massively parallel process, that can be a lot of seeds!\n",
    "\n",
    "In Numba, the functions that spawn and use these generators are called `nb.cuda.random.*xoroshiro128p*` ([see documentation](https://numba.readthedocs.io/en/stable/cuda/random.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf97866-b0e6-4100-a6bf-1a31bdaa57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.cuda.random import create_xoroshiro128p_states\n",
    "from numba.cuda.random import xoroshiro128p_uniform_float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9545e-1dfa-44c8-83e1-4c6091e70998",
   "metadata": {},
   "source": [
    "This generates 10000 generators (outside of the kernel) and then runs each generator for 1000 steps (inside the kernel) to get 10000 × 1000 random floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c3bcd-c600-4222-90ba-f8ec64fb3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.cuda.jit\n",
    "def generate_uniform(rng_states, out):\n",
    "    thread_idx = nb.cuda.grid(1)\n",
    "    for j in range(1000):\n",
    "        out[thread_idx, j] = xoroshiro128p_uniform_float32(rng_states, thread_idx)\n",
    "\n",
    "out = cp.empty((10000, 1000), dtype=np.float32)\n",
    "\n",
    "threads_per_block = 1024\n",
    "blocks_per_grid = int(np.ceil(len(out) / 1024))\n",
    "\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block * blocks_per_grid, seed=12345)\n",
    "\n",
    "generate_uniform[blocks_per_grid, threads_per_block](rng_states, out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfac7de-d905-41e6-a6f1-5cfec4381f04",
   "metadata": {},
   "source": [
    "For performance, there's a balance between having enough blocks to keep the whole GPU busy and having to spawn such a large number of generators (outside the kernel) that the spawning process takes more time than the GPU kernel.\n",
    "\n",
    "In this exercise, you need to sample random number pairs $x \\in (-1, 1)$, $y \\in (-1, 1)$ with a uniform distribution to compute the area of a circle with radius $r = 1$. Then use the area $A = \\pi r^2$ formula to derive $\\pi$.\n",
    "\n",
    "* How does the accuracy depend on number of sampled pairs?\n",
    "* What about the computation time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
